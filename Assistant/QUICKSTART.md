# ğŸš€ Szybki Start

## 1. SprawdÅº czy Ollama dziaÅ‚a

```bash
ollama list
```

PowinieneÅ› zobaczyÄ‡ `llama3.1:8b`. JeÅ›li nie ma, pobierz:
```bash
ollama pull llama3.1:8b
```

## 2. Zainstaluj zaleÅ¼noÅ›ci (jeÅ›li jeszcze nie)

```bash
cd Assistant
pip install -r requirements.txt
```

## 3. Pobierz aktualne informacje o komunikacji (opcjonalnie)

```bash
python traffic_scraper.py
```

Lub uÅ¼yj prostszego skryptu:
```bash
python update_traffic.py
```

## 4. Uruchom serwer LLM

W jednym terminalu:
```bash
cd Assistant
python integrated_server.py
```

Serwer bÄ™dzie dostÄ™pny na `http://localhost:8000`

## 5. Przetestuj system

W drugim terminalu:
```bash
cd Assistant
python test_llm.py
```

## 6. UÅ¼yj API

### PrzykÅ‚ad z Python:

```python
import requests

response = requests.post("http://localhost:8000/chat", json={
    "messages": [
        {"role": "user", "content": "Jakie sÄ… zmiany w rozkÅ‚adach jazdy?"}
    ],
    "include_traffic_info": True
})

print(response.json()["message"])
```

### PrzykÅ‚ad z curl:

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Czy sÄ… jakieÅ› utrudnienia w ruchu?"}
    ],
    "include_traffic_info": true
  }'
```

## 7. Aktualizuj informacje o komunikacji

```bash
curl -X POST http://localhost:8000/update-traffic-info
```

## Przydatne endpointy:

- `GET /` - Status serwera
- `POST /chat` - Rozmowa z LLM
- `GET /traffic-info` - Pobierz informacje o komunikacji
- `POST /update-traffic-info` - Zaktualizuj informacje
- `GET /models` - Lista dostÄ™pnych modeli

## PrzykÅ‚adowe pytania:

- "Jakie sÄ… aktualne zmiany w rozkÅ‚adach jazdy?"
- "Czy sÄ… jakieÅ› utrudnienia w ruchu?"
- "KtÃ³re linie tramwajowe sÄ… zmienione?"
- "Gdzie sÄ… remonty drÃ³g?"
- "Czy linia 6 kursuje normalnie?"
- "Jakie sÄ… planowane remonty ulic?"

